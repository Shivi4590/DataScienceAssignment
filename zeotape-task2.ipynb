{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10592749,"sourceType":"datasetVersion","datasetId":6556111}],"dockerImageVersionId":30839,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":" import pandas as pd\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Create sample data\ndef create_sample_data():\n    # Create Customers data\n    customers_data = {\n        'CustomerID': [f'C{str(i).zfill(4)}' for i in range(1, 101)],\n        'Region': np.random.choice(['North', 'South', 'East', 'West'], 100)\n    }\n    customers_df = pd.DataFrame(customers_data)\n\n    # Create Products data\n    products_data = {\n        'ProductID': [f'P{str(i).zfill(4)}' for i in range(1, 21)],\n        'Category': np.random.choice(['Electronics', 'Clothing', 'Books', 'Home'], 20)\n    }\n    products_df = pd.DataFrame(products_data)\n\n    # Create Transactions data\n    transactions = []\n    for i in range(1000):\n        transactions.append({\n            'TransactionID': f'T{str(i).zfill(4)}',\n            'CustomerID': np.random.choice(customers_df['CustomerID']),\n            'ProductID': np.random.choice(products_df['ProductID']),\n            'TotalValue': np.random.uniform(10, 1000, 1)[0]\n        })\n    transactions_df = pd.DataFrame(transactions)\n    \n    return customers_df, products_df, transactions_df\n\n# Load or create data\nprint(\"Creating sample data...\")\ncustomers_df, products_df, transactions_df = create_sample_data()\n\nprint(\"Data created successfully!\")\nprint(f\"Customers shape: {customers_df.shape}\")\nprint(f\"Products shape: {products_df.shape}\")\nprint(f\"Transactions shape: {transactions_df.shape}\")\n\n# Create transaction summary\nprint(\"\\nCreating transaction summary...\")\ntransactions_summary = transactions_df.groupby(\"CustomerID\").agg({\n    \"TotalValue\": [\"sum\", \"mean\"],\n    \"TransactionID\": \"count\"\n}).reset_index()\n\n# Flatten column names\ntransactions_summary.columns = [\"CustomerID\", \"total_spent\", \"avg_spent\", \"num_transactions\"]\n\n# Create product preferences\nprint(\"Creating product preferences...\")\nproduct_transactions = pd.merge(transactions_df, products_df, on=\"ProductID\")\ncustomer_preferences = product_transactions.groupby([\"CustomerID\", \"Category\"]).agg({\n    \"TotalValue\": \"sum\"\n}).reset_index()\n\n# Create pivot table for customer preferences\ncustomer_preferences_pivot = customer_preferences.pivot(\n    index=\"CustomerID\",\n    columns=\"Category\",\n    values=\"TotalValue\"\n).fillna(0)\n\n# Normalize preferences (row-wise)\ncustomer_preferences_pivot = customer_preferences_pivot.div(\n    customer_preferences_pivot.sum(axis=1), axis=0\n)\n\n# Merge customer data with transaction summary\nprint(\"Merging customer data...\")\ncustomers_merged = pd.merge(\n    customers_df,\n    transactions_summary,\n    on=\"CustomerID\",\n    how=\"left\"\n).fillna(0)\n\n# Prepare features for similarity calculation\nprint(\"Preparing features...\")\n\n# Categorical features (Region)\nencoder = OneHotEncoder(sparse=False)\nregion_encoded = encoder.fit_transform(customers_merged[[\"Region\"]])\nregion_cols = [f\"region_{cat}\" for cat in encoder.categories_[0]]\n\n# Scale numerical features\nscaler = StandardScaler()\nnumerical_features = [\"total_spent\", \"avg_spent\", \"num_transactions\"]\nscaled_numerical = scaler.fit_transform(customers_merged[numerical_features])\n\n# Align customer preferences with the customer data (handle missing categories)\nfinal_customer_preferences = customer_preferences_pivot.reindex(customers_merged[\"CustomerID\"]).fillna(0)\n\n# Combine all features: region + scaled numerical features + customer preferences\nfinal_features = np.hstack([\n    region_encoded,\n    scaled_numerical,\n    final_customer_preferences.values\n])\n\n# Calculate similarity matrix\nprint(\"Calculating similarity matrix...\")\nsimilarity_matrix = cosine_similarity(final_features)\n\n# Function to get top similar customers\ndef get_top_similar(similarity_matrix, customer_index, customer_ids, top_n=3):\n    similarity_scores = similarity_matrix[customer_index]\n    similarity_scores[customer_index] = -1  # Exclude self-similarity\n    top_indices = similarity_scores.argsort()[::-1][:top_n]\n    return [(customer_ids[i], similarity_scores[i]) for i in top_indices]\n\n# Generate recommendations for first 20 customers\nprint(\"Generating recommendations...\")\nlookalike_results = []\ncustomer_ids = customers_merged[\"CustomerID\"].tolist()\n\nfor i in range(min(20, len(customer_ids))):\n    customer_id = customer_ids[i]\n    similar_customers = get_top_similar(similarity_matrix, i, customer_ids)\n    row = [customer_id] + [item for sublist in similar_customers for item in sublist]\n    lookalike_results.append(row)\n\n# Create and save results\ncolumns = [\"cust_id\", \"lookalike_1\", \"score_1\", \"lookalike_2\", \"score_2\", \"lookalike_3\", \"score_3\"]\nlookalike_df = pd.DataFrame(lookalike_results, columns=columns)\n\n# Save results\nprint(\"Saving results...\")\nlookalike_df.to_csv(\"Lookalike.csv\", index=False)\nprint(\"\\nResults saved to Lookalike.csv\")\n\n# Display results\nprint(\"\\nLookalike Results (First 5 rows):\")\nprint(lookalike_df.head())\n\n# Print some statistics\nprint(\"\\nSummary Statistics:\")\nprint(f\"Total number of recommendations generated: {len(lookalike_df)}\")\nprint(f\"Average similarity score: {lookalike_df[['score_1', 'score_2', 'score_3']].mean().mean():.3f}\")\n\n# Display example insights\nprint(\"\\nExample Insights:\")\nprint(\"1. Top 3 most similar pairs:\")\ntop_pairs = lookalike_df.nlargest(3, 'score_1')[['cust_id', 'lookalike_1', 'score_1']]\nprint(top_pairs)\n\nprint(\"\\n2. Distribution of similarity scores:\")\nall_scores = pd.concat([\n    lookalike_df['score_1'],\n    lookalike_df['score_2'],\n    lookalike_df['score_3']\n])\nprint(all_scores.describe())\n\nprint(\"\\nProcess completed successfully!\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T16:02:03.110130Z","iopub.execute_input":"2025-01-27T16:02:03.110477Z","iopub.status.idle":"2025-01-27T16:02:03.251472Z","shell.execute_reply.started":"2025-01-27T16:02:03.110449Z","shell.execute_reply":"2025-01-27T16:02:03.250337Z"}},"outputs":[{"name":"stdout","text":"Creating sample data...\nData created successfully!\nCustomers shape: (100, 2)\nProducts shape: (20, 2)\nTransactions shape: (1000, 4)\n\nCreating transaction summary...\nCreating product preferences...\nMerging customer data...\nPreparing features...\nCalculating similarity matrix...\nGenerating recommendations...\nSaving results...\n\nResults saved to Lookalike.csv\n\nLookalike Results (First 5 rows):\n  cust_id lookalike_1   score_1 lookalike_2   score_2 lookalike_3   score_3\n0   C0001       C0044  0.985900       C0049  0.969533       C0047  0.890907\n1   C0002       C0093  0.938874       C0037  0.936726       C0056  0.922008\n2   C0003       C0076  0.971569       C0043  0.928285       C0035  0.883669\n3   C0004       C0091  0.984061       C0086  0.944462       C0010  0.922448\n4   C0005       C0084  0.928950       C0061  0.920700       C0022  0.902655\n\nSummary Statistics:\nTotal number of recommendations generated: 20\nAverage similarity score: 0.925\n\nExample Insights:\n1. Top 3 most similar pairs:\n   cust_id lookalike_1   score_1\n13   C0014       C0096  0.993611\n7    C0008       C0070  0.990481\n0    C0001       C0044  0.985900\n\n2. Distribution of similarity scores:\ncount    60.000000\nmean      0.925372\nstd       0.051205\nmin       0.775155\n25%       0.897487\n50%       0.936139\n75%       0.968517\nmax       0.993611\ndtype: float64\n\nProcess completed successfully!\n","output_type":"stream"}],"execution_count":11}]}